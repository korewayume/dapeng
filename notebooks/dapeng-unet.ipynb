{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, Input, merge, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, Input, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_coefficient(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "def jaccard_coefficient_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "def get_unet(size):\n",
    "    inputs = Input(shape=(size, size, 3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPool2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=[jaccard_coefficient])\n",
    "    \n",
    "    with open(\"u-net-model.yaml\", \"w+\") as mf:\n",
    "        mf.write(model.to_yaml())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(x_train, y_train, x_val, y_val, epochs):\n",
    "    print(u\"开始训练网络\")\n",
    "    \n",
    "    model = get_unet(160)\n",
    "    try:\n",
    "        model.load_weights('weights/unet_best.hdf5')\n",
    "    except IOError as e:\n",
    "        pass\n",
    "    model_checkpoint = ModelCheckpoint('weights/unet_best.hdf5', monitor='loss', save_best_only=True, verbose=0)\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=epochs, verbose=1, shuffle=True,\n",
    "              callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip_into_peices(dapeng_image, dapeng_mask=None, horizontal_step=160, vertical_step=160, ):\n",
    "#     assert dapeng_image.shape[:2]==dapeng_mask.shape[:2]\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for i in range(dapeng_image.shape[0]/horizontal_step):\n",
    "        for j in range(dapeng_image.shape[1]/vertical_step):\n",
    "            idx_1 = i*horizontal_step\n",
    "            idx_2 = idx_1+horizontal_step\n",
    "            idx_3 = j*vertical_step\n",
    "            idx_4 = idx_3+vertical_step\n",
    "            x_data.append(dapeng_image[idx_1:idx_2,idx_3:idx_4])\n",
    "            if dapeng_mask is not None:\n",
    "                y_data.append(dapeng_mask[idx_1:idx_2,idx_3:idx_4])\n",
    "    return np.stack(x_data), np.stack(y_data) if y_data else None\n",
    "\n",
    "def stick_image(peices_array, size, num_of_row, num_of_col):\n",
    "    rv = np.zeros((num_of_row*size, num_of_col*size), dtype=np.float32)\n",
    "    for i in range(num_of_row):\n",
    "        for j in range(num_of_col):\n",
    "            rv[i*size:i*size+size,j*size:j*size+size] = pred_y[i*num_of_col+j].reshape(size,size)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dapeng_validation_mask = cv2.imread(\"dapeng_validation_mask.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# dapeng_validation_mask[dapeng_validation_mask!=0]=1\n",
    "# dapeng_validation = cv2.imread(\"dapeng_validation.png\")[:dapeng_validation_mask.shape[0], :dapeng_validation_mask.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_data, y_data = clip_into_peices(dapeng_validation, dapeng_validation_mask)\n",
    "# index = []\n",
    "# for idx, data in enumerate(y_data):\n",
    "#     if not np.all(data==0):\n",
    "#         index.append(idx)\n",
    "# y_data = y_data.reshape(y_data.shape[0], y_data.shape[1], y_data.shape[2], 1)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_data[index], y_data[index], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trained_model = train_net(x_train, y_train, x_test, y_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dapeng_train = cv2.imread(\"/root/MLCookbook/notebooks/dapeng/dapeng_train.png\")\n",
    "# pred_x, _ = clip_into_peices(dapeng_train)\n",
    "# pred_y = trained_model.predict(pred_x)\n",
    "# num_of_row, num_of_col = dapeng_train.shape[0]/160, dapeng_train.shape[1]/160\n",
    "# result = stick_image(pred_y, 160, num_of_row, num_of_col)\n",
    "# cv2.imwrite(\"result.png\", result*255)\n",
    "# plt.imshow(result, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = get_unet(160)\n",
    "# trained_model.load_weights('weights/unet_best.hdf5')\n",
    "# pred_y = trained_model.predict(x_data[index][:5])\n",
    "# fig = plt.figure(figsize=(15,15))\n",
    "# for i in range(5):\n",
    "#     plt.subplot(5,2,i*2+1)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(x_data[index][:5][i][:,:,::-1])\n",
    "#     plt.subplot(5,2,i*2+2)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(pred_y[i].reshape(160,160), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dapeng_train = cv2.imread(\"/root/notebooks/MLCookbook/notebooks/dapeng/dapeng_train.png\")\n",
    "# pred_x, _ = clip_into_peices(dapeng_train)\n",
    "# num_of_row, num_of_col = dapeng_train.shape[0]/160, dapeng_train.shape[1]/160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = trained_model.predict(pred_x[20].reshape(1, 160, 160, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.axis(\"off\")\n",
    "# plt.imshow(pred_x[20][:,:,::-1])\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.axis(\"off\")\n",
    "# plt.imshow(y[0].reshape(160,160), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model = get_unet(160)\n",
    "trained_model.load_weights('weights/unet_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "pred_x = sorted(glob(\"pieces/*.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
