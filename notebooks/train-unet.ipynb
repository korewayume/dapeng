{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, UpSampling2D, Input, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mosaic_size = 256\n",
    "unet_model_path = \"test/u-net-model.yaml\"\n",
    "unet_weight_path = 'test/unet_best.hdf5'\n",
    "unet_weight_checkpoint_path = 'test/unet_best_checkpoint.hdf5'\n",
    "batch_size = 14\n",
    "epochs = 10\n",
    "tensorboard_log_directory = \"/root/notebooks/tensorflow_logs\"\n",
    "load_weigth = False\n",
    "learning_rate = 1e-4\n",
    "fit_verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_coefficient(output, target, axis=[1,2,3], smooth=1e-5):\n",
    "    \"\"\"Jaccard coefficient for comparing the similarity of two\n",
    "    batch of data, usually be used for binary image segmentation.\n",
    "    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    output : tensor\n",
    "        A distribution with shape: [batch_size, ....], (any dimensions).\n",
    "    target : tensor\n",
    "        A distribution with shape: [batch_size, ....], (any dimensions).\n",
    "    axis : list of integer\n",
    "        All dimensions are reduced, default ``[1,2,3]``.\n",
    "    smooth : float\n",
    "        This small value will be added to the numerator and denominator.\n",
    "        If both output and target are empty, it makes sure dice is 1.\n",
    "        If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``,\n",
    "        then if smooth is very small, dice close to 0 (even the image values lower than the threshold),\n",
    "        so in this case, higher smooth can have a higher dice.\n",
    "        \n",
    "    Examples\n",
    "    ---------\n",
    "    >>> a = tf.constant([[[[1],[0]],[[1],[1]]]],dtype=tf.float64)\n",
    "    >>> b = tf.constant([[[[1],[1]],[[1],[1]]]],dtype=tf.float64)\n",
    "    >>> val = jaccard_coefficient(a,b)\n",
    "    >>> session = tf.Session()\n",
    "    >>> session.run(val)\n",
    "\n",
    "    References\n",
    "    -----------\n",
    "    - `Jaccard coefficient <https://en.wikipedia.org/wiki/Jaccard_index>`_\n",
    "    \"\"\"\n",
    "    inse = K.sum(output * target, axis=axis)\n",
    "    l = K.sum(output * output, axis=axis)\n",
    "    r = K.sum(target * target, axis=axis)\n",
    "    dice = (2. * inse + smooth) / (l + r + smooth)\n",
    "    return K.mean(dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"unet-5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet(size):\n",
    "    inputs = Input(shape=(size, size, 3))\n",
    "    \n",
    "# left\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    \n",
    "    pool4 = MaxPool2D(pool_size=(2, 2))(conv4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "# right\n",
    "    \n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
    "    # dropout\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
    "    # dropout\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
    "    # dropout\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
    "    # dropout\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=[jaccard_coefficient])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(x_train, y_train, x_val, y_val, load_weigth=load_weigth):\n",
    "    print(u\"开始训练网络\")\n",
    "    \n",
    "    model = get_unet(mosaic_size)\n",
    "    \n",
    "    with open(unet_model_path, \"w+\") as mf:\n",
    "        mf.write(model.to_yaml())\n",
    "    if load_weigth:\n",
    "        model.load_weights(unet_weight_path)\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(unet_weight_checkpoint_path, monitor='loss', save_best_only=True, verbose=0)\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=tensorboard_log_directory, write_graph=True, write_images=True)\n",
    "    \n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=fit_verbose, shuffle=True,\n",
    "              callbacks=[model_checkpoint, tensorboard], validation_data=(x_val, y_val))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.load(\"x_data.npy\")\n",
    "y_data = np.load(\"y_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = []\n",
    "for idx, data in enumerate(y_data):\n",
    "    if not np.all(data==0):\n",
    "        index.append(idx)\n",
    "y_data = y_data.reshape(y_data.shape[0], y_data.shape[1], y_data.shape[2], 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data[index], y_data[index], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_net(x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
